{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce51438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for environment setup and API key handling\n",
    "import getpass\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Load environment variables from .env file (if it exists)\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "# Check if Google API key is already set in environment variables\n",
    "# If not, prompt user to enter it securely (input will be hidden)\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "\n",
    "# Import LangChain's chat model initialization function\n",
    "\n",
    "# Initialize the Gemini 2.5 Flash model\n",
    "# This creates a chat model instance that we can use to interact with the AI\n",
    "google_model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "openai_model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "anthropic_model = init_chat_model(\"claude-3-5-sonnet-20241022\", model_provider=\"anthropic\")\n",
    "model = openai_model\n",
    "\n",
    "print(\"âœ… Model initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8012ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response (without context):\n",
      "I don't have access to personal information about users unless it's provided in the conversation. So I don't know your name. If you'd like to share it, feel free!\n",
      "\n",
      "==================================================\n",
      "Notice: The model doesn't remember the previous conversation!\n",
      "This makes for a terrible chatbot experience.\n"
     ]
    }
   ],
   "source": [
    "# Ask a follow-up question without providing conversation context\n",
    "# Since the model is stateless, it won't remember that we said our name is Bob\n",
    "response = model.invoke([HumanMessage(content=\"What's my name?\")])\n",
    "\n",
    "print(\"AI Response (without context):\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Notice: The model doesn't remember the previous conversation!\")\n",
    "print(\"This makes for a terrible chatbot experience.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c45c49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response (with conversation history):\n",
      "Your name is Bob! How can I help you today, Bob?\n",
      "\n",
      "==================================================\n",
      "Success! Now the model remembers the conversation context.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import AIMessage to represent responses from the AI model\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# Create a conversation history with multiple turns\n",
    "# This simulates a real conversation where context is maintained\n",
    "conversation_history = [\n",
    "    HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "    AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "    HumanMessage(content=\"What's my name?\"),\n",
    "]\n",
    "\n",
    "# Pass the entire conversation history to the model\n",
    "# Now the model has context and can answer the follow-up question correctly\n",
    "response = model.invoke(conversation_history)\n",
    "\n",
    "print(\"AI Response (with conversation history):\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Success! Now the model remembers the conversation context.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d463da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Chat (type 'quit' to exit)\n",
      "Hey how are you\n",
      "ðŸ¤– AI: I'm just a program, but I'm here and ready to help you! How can I assist you today?\n",
      "\n",
      "ðŸ¤– AI: It looks like your message didn't come through. How can I assist you?\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    conversation = []\n",
    "    print(\"ðŸ¤– Chat (type 'quit' to exit)\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"ï¿½ï¿½ You: \")\n",
    "        print(f\"User input: {user_input}\")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        conversation.append(HumanMessage(content=user_input))\n",
    "        response = model.invoke(conversation)\n",
    "        conversation.append(response)\n",
    "        print(f\"ðŸ¤– AI: {response.content}\")\n",
    "\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f739f30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup: Why are cats so good at video games?\n",
      "Punchline: Because they have 9 lives, of course!\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Pydantic model for a single joke\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "\n",
    "# New Pydantic model for a list of jokes\n",
    "class JokeList(BaseModel):\n",
    "    \"\"\"A list of jokes.\"\"\"\n",
    "    jokes: List[Joke] = Field(description=\"A list of jokes to tell the user.\")\n",
    "\n",
    "# Instantiate the structured LLM with the new model\n",
    "structured_llm_multi = model.with_structured_output(JokeList)\n",
    "\n",
    "# Invoke the LLM, specifying how many jokes you want\n",
    "response = structured_llm_multi.invoke(f\"\"\"parse this text to cat's jokes {input('input here')}\"\"\")\n",
    "\n",
    "# Now you can iterate over the list of joke objects\n",
    "for joke_obj in response.jokes:\n",
    "    print(f\"Setup: {joke_obj.setup}\")\n",
    "    print(f\"Punchline: {joke_obj.punchline}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef356db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Chat (type 'quit' to exit)\n",
      "User input: hello how are you\n",
      "ðŸ¤– AI: Hello! I'm just a program, so I don't have feelings, but I'm here to help you. How can I assist you today?\n",
      "Sentiment: neutral\n",
      "User input: I reely feel great today\n",
      "ðŸ¤– AI: That's wonderful to hear! I'm glad you're feeling great today. Is there anything special you're doing to celebrate your good mood?\n",
      "Sentiment: positive\n",
      "User input: now i feel not so well\n",
      "ðŸ¤– AI: I'm sorry to hear that you're not feeling well now. If you'd like to talk about it or if there's anything I can do to help, please let me know.\n",
      "Sentiment: negative\n",
      "User input: quit\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# 1. Define your Pydantic model\n",
    "class ChatResponse(BaseModel):\n",
    "    \"\"\"A structured response from the chat assistant.\"\"\"\n",
    "    message: str = Field(description=\"The chat assistant's primary message.\")\n",
    "    sentiment: Optional[str] = Field(description=\"The sentiment of the user's message (e.g., positive, negative, neutral).\")\n",
    "\n",
    "# 2. Define the chat function that will use the structured model\n",
    "def chat_with_pydentic_model(model):\n",
    "    conversation = []\n",
    "    print(\"ðŸ¤– Chat (type 'quit' to exit)\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"ðŸ™‚ You: \")\n",
    "        print(f\"User input: {user_input}\")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "\n",
    "        # Step 1: Append the user's message to the conversation\n",
    "        conversation.append(HumanMessage(content=user_input))\n",
    "        \n",
    "        # Step 2: Invoke the model with the updated conversation history\n",
    "        response_obj = model.invoke(conversation)\n",
    "\n",
    "        # Step 3: Append the AI's response as an AIMessage object\n",
    "        conversation.append(AIMessage(content=response_obj.message))\n",
    "        \n",
    "        # Now, print the response from the Pydantic object\n",
    "        print(f\"ðŸ¤– AI: {response_obj.message}\")\n",
    "        if hasattr(response_obj, 'sentiment'):\n",
    "            print(f\"Sentiment: {response_obj.sentiment}\")\n",
    "\n",
    "\n",
    "# 4. Bind the Pydantic schema to the base LLM to create the structured model\n",
    "structured_llm = model.with_structured_output(ChatResponse)\n",
    "\n",
    "# 5. Call the function with the new, structured model\n",
    "chat_with_pydentic_model(model=structured_llm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
